{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('/F_MNIST_data', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "testset = datasets.FashionMNIST('/F_MNIST_data', download = True, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19fc61dc128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.dropout = nn.Dropout(p = drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "        images.resize_(images.shape[0], 784)\n",
    "        output = model(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "        \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, criterion, optimizer, epochs = 5, print_every = 40):\n",
    "    steps = 0\n",
    "    train_loss = 0\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            images.resize_(images.shape[0], 784)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print('Epoch {}/{}..'.format(e+1, epochs),\n",
    "                     'Training Loss: {:.3f}..'.format(train_loss/print_every),\n",
    "                     'Test Loss: {:.3f}..'.format(test_loss/len(testloader)),\n",
    "                     'Test Accuracy: {:.3f}..'.format(accuracy/len(testloader)))\n",
    "                \n",
    "                train_loss = 0\n",
    "                \n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2.. Training Loss: 0.894.. Test Loss: 0.710.. Test Accuracy: 0.731..\n",
      "Epoch 1/2.. Training Loss: 0.833.. Test Loss: 0.698.. Test Accuracy: 0.735..\n",
      "Epoch 1/2.. Training Loss: 0.792.. Test Loss: 0.629.. Test Accuracy: 0.766..\n",
      "Epoch 1/2.. Training Loss: 0.763.. Test Loss: 0.621.. Test Accuracy: 0.765..\n",
      "Epoch 1/2.. Training Loss: 0.775.. Test Loss: 0.655.. Test Accuracy: 0.758..\n",
      "Epoch 1/2.. Training Loss: 0.809.. Test Loss: 0.613.. Test Accuracy: 0.775..\n",
      "Epoch 1/2.. Training Loss: 0.801.. Test Loss: 0.631.. Test Accuracy: 0.777..\n",
      "Epoch 1/2.. Training Loss: 0.756.. Test Loss: 0.602.. Test Accuracy: 0.776..\n",
      "Epoch 1/2.. Training Loss: 0.767.. Test Loss: 0.660.. Test Accuracy: 0.774..\n",
      "Epoch 1/2.. Training Loss: 0.777.. Test Loss: 0.575.. Test Accuracy: 0.789..\n",
      "Epoch 1/2.. Training Loss: 0.783.. Test Loss: 0.558.. Test Accuracy: 0.808..\n",
      "Epoch 1/2.. Training Loss: 0.764.. Test Loss: 0.573.. Test Accuracy: 0.803..\n",
      "Epoch 1/2.. Training Loss: 0.769.. Test Loss: 0.636.. Test Accuracy: 0.783..\n",
      "Epoch 1/2.. Training Loss: 0.777.. Test Loss: 0.551.. Test Accuracy: 0.802..\n",
      "Epoch 1/2.. Training Loss: 0.730.. Test Loss: 0.574.. Test Accuracy: 0.791..\n",
      "Epoch 1/2.. Training Loss: 0.741.. Test Loss: 0.557.. Test Accuracy: 0.799..\n",
      "Epoch 1/2.. Training Loss: 0.763.. Test Loss: 0.577.. Test Accuracy: 0.803..\n",
      "Epoch 1/2.. Training Loss: 0.726.. Test Loss: 0.554.. Test Accuracy: 0.806..\n",
      "Epoch 1/2.. Training Loss: 0.724.. Test Loss: 0.550.. Test Accuracy: 0.809..\n",
      "Epoch 1/2.. Training Loss: 0.721.. Test Loss: 0.539.. Test Accuracy: 0.817..\n",
      "Epoch 1/2.. Training Loss: 0.693.. Test Loss: 0.536.. Test Accuracy: 0.808..\n",
      "Epoch 1/2.. Training Loss: 0.704.. Test Loss: 0.556.. Test Accuracy: 0.809..\n",
      "Epoch 1/2.. Training Loss: 0.673.. Test Loss: 0.530.. Test Accuracy: 0.812..\n",
      "Epoch 2/2.. Training Loss: 0.680.. Test Loss: 0.535.. Test Accuracy: 0.810..\n",
      "Epoch 2/2.. Training Loss: 0.719.. Test Loss: 0.574.. Test Accuracy: 0.798..\n",
      "Epoch 2/2.. Training Loss: 0.692.. Test Loss: 0.521.. Test Accuracy: 0.816..\n",
      "Epoch 2/2.. Training Loss: 0.723.. Test Loss: 0.551.. Test Accuracy: 0.804..\n",
      "Epoch 2/2.. Training Loss: 0.644.. Test Loss: 0.521.. Test Accuracy: 0.818..\n",
      "Epoch 2/2.. Training Loss: 0.699.. Test Loss: 0.518.. Test Accuracy: 0.818..\n",
      "Epoch 2/2.. Training Loss: 0.649.. Test Loss: 0.532.. Test Accuracy: 0.818..\n",
      "Epoch 2/2.. Training Loss: 0.736.. Test Loss: 0.535.. Test Accuracy: 0.819..\n",
      "Epoch 2/2.. Training Loss: 0.745.. Test Loss: 0.557.. Test Accuracy: 0.807..\n",
      "Epoch 2/2.. Training Loss: 0.746.. Test Loss: 0.509.. Test Accuracy: 0.818..\n",
      "Epoch 2/2.. Training Loss: 0.672.. Test Loss: 0.512.. Test Accuracy: 0.818..\n",
      "Epoch 2/2.. Training Loss: 0.705.. Test Loss: 0.533.. Test Accuracy: 0.811..\n",
      "Epoch 2/2.. Training Loss: 0.655.. Test Loss: 0.521.. Test Accuracy: 0.821..\n",
      "Epoch 2/2.. Training Loss: 0.666.. Test Loss: 0.520.. Test Accuracy: 0.822..\n",
      "Epoch 2/2.. Training Loss: 0.706.. Test Loss: 0.528.. Test Accuracy: 0.810..\n",
      "Epoch 2/2.. Training Loss: 0.630.. Test Loss: 0.506.. Test Accuracy: 0.821..\n",
      "Epoch 2/2.. Training Loss: 0.633.. Test Loss: 0.502.. Test Accuracy: 0.830..\n",
      "Epoch 2/2.. Training Loss: 0.698.. Test Loss: 0.514.. Test Accuracy: 0.824..\n",
      "Epoch 2/2.. Training Loss: 0.650.. Test Loss: 0.491.. Test Accuracy: 0.823..\n",
      "Epoch 2/2.. Training Loss: 0.679.. Test Loss: 0.532.. Test Accuracy: 0.811..\n",
      "Epoch 2/2.. Training Loss: 0.700.. Test Loss: 0.541.. Test Accuracy: 0.806..\n",
      "Epoch 2/2.. Training Loss: 0.650.. Test Loss: 0.550.. Test Accuracy: 0.817..\n",
      "Epoch 2/2.. Training Loss: 0.719.. Test Loss: 0.531.. Test Accuracy: 0.824..\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, testloader, criterion, optimizer, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print('Our model: \\n\\n', model, '\\n')\n",
    "print('The state dict keys: \\n\\n', model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e50b086791a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Python Virtual Environments\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 719\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model."
     ]
    }
   ],
   "source": [
    "model2 = Network(784, 10, [400, 200, 100])\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "             'output_size': 10,\n",
    "             'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "             'state_dict': model.state_dict()}\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network(checkpoint['input_size'],\n",
    "                   checkpoint['output_size'],\n",
    "                   checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
